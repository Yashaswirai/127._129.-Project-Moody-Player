# ğŸµ Moody Player

A smart music player that uses facial expression recognition to detect your mood and automatically plays music that matches your emotional state.

## ğŸŒŸ Features

- **Real-time Facial Expression Detection**: Uses your webcam to analyze facial expressions and detect emotions
- **Mood-based Music Recommendation**: Automatically fetches and plays songs based on your detected mood
- **Music Upload & Management**: Upload your own music files and categorize them by mood
- **AI-Powered Mood Categorization**: Uploaded music gets automatically categorized to appropriate moods using Gemini API
- **Responsive Music Player**: Clean, intuitive interface for playing, pausing, and managing your music
- **Multiple Mood Categories**: Supports Happy, Sad, Energetic, Calm, Romantic, Angry, and Nostalgic moods

## ğŸ—ï¸ Architecture

The project consists of two main components:

### Frontend (React + Vite)
- **Technology Stack**: React 19, Vite, TailwindCSS, Face-API.js
- **Key Components**:
  - `FacialExpression`: Handles webcam access and emotion detection
  - `MusicPlayers`: Manages music playback and display
  - `UploadMusic`: Handles music file uploads with mood categorization

### Backend (Node.js + Express)
- **Technology Stack**: Node.js, Express, MongoDB, Mongoose
- **Key Features**:
  - RESTful API for song management
  - File upload handling with Multer
  - Cloud storage integration with ImageKit
  - MongoDB database for song metadata

## ğŸš€ Getting Started

### Prerequisites

- Node.js (v16 or higher)
- MongoDB database
- ImageKit account for file storage
- Webcam for facial expression detection

### Environment Variables

Create `.env` files in both Frontend and Backend directories:

#### Backend `.env`
```env
PORT=3000
MONGODB_URI=your_mongodb_connection_string
IMAGEKIT_PUBLIC_KEY=your_imagekit_public_key
IMAGEKIT_PRIVATE_KEY=your_imagekit_private_key
IMAGEKIT_URL_ENDPOINT=your_imagekit_url_endpoint
```

#### Frontend `.env`
```env
VITE_API_URL=http://localhost:3000/api
```

### Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd moody-player
   ```

2. **Install Backend Dependencies**
   ```bash
   cd Backend
   npm install
   ```

3. **Install Frontend Dependencies**
   ```bash
   cd Frontend
   npm install
   ```

4. **Start the Backend Server**
   ```bash
   cd Backend
   npm start
   ```

5. **Start the Frontend Development Server**
   ```bash
   cd Frontend
   npm run dev
   ```

6. **Access the Application**
   - Open your browser and navigate to `http://localhost:5173`
   - Allow webcam access when prompted

## ğŸ“ Project Structure

```
moody-player/
â”œâ”€â”€ Backend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â””â”€â”€ song.model.js          # MongoDB song schema
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â””â”€â”€ song.route.js          # API routes for songs
â”‚   â”‚   â”œâ”€â”€ Services/
â”‚   â”‚   â”‚   â””â”€â”€ Storage.Service.js     # ImageKit integration
â”‚   â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”‚   â””â”€â”€ db.js                  # Database connection
â”‚   â”‚   â””â”€â”€ app.js                     # Express app configuration
â”‚   â”œâ”€â”€ uploads/                       # Temporary upload directory
â”‚   â”œâ”€â”€ Server.js                      # Server entry point
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ Frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ Components/
â”‚   â”‚   â”‚   â”œâ”€â”€ FacialExpression.jsx   # Emotion detection component
â”‚   â”‚   â”‚   â”œâ”€â”€ MusicPlayers.jsx       # Music player component
â”‚   â”‚   â”‚   â””â”€â”€ UploadMusic.jsx        # Music upload component
â”‚   â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”‚   â””â”€â”€ API.js                 # Axios configuration
â”‚   â”‚   â”œâ”€â”€ App.jsx                    # Main app component
â”‚   â”‚   â””â”€â”€ main.jsx                   # React entry point
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â””â”€â”€ models/                    # Face-API.js ML models
â”‚   â””â”€â”€ package.json
â””â”€â”€ README.md
```

## ğŸ¯ How It Works

1. **Emotion Detection**: The application accesses your webcam and uses Face-API.js to detect facial expressions in real-time
2. **Mood Mapping**: Detected expressions are mapped to mood categories (happy, sad, energetic, etc.)
3. **Music Fetching**: Based on the detected mood, the app queries the backend for songs matching that mood
4. **Music Playback**: Retrieved songs are displayed in the music player interface where you can play, pause, and browse tracks
5. **Music Upload**: Users can upload their own music files which get automatically categorized by mood using Gemini API for intelligent classification

## ğŸ› ï¸ API Endpoints

### Songs
- `POST /api/song` - Upload a new song with mood categorization
- `GET /api/song?mood={mood}` - Fetch songs by mood category

## ğŸ¨ Supported Moods

- **Happy** - Upbeat, joyful music
- **Sad** - Melancholic, emotional tracks
- **Energetic** - High-energy, motivational songs
- **Calm** - Peaceful, relaxing music
- **Romantic** - Love songs and romantic ballads
- **Angry** - Intense, aggressive tracks
- **Nostalgic** - Throwback and sentimental music

## ğŸ”§ Technologies Used

### Frontend
- React 19
- Vite
- TailwindCSS
- Face-API.js
- Axios
- React Hook Form

### Backend
- Node.js
- Express.js
- MongoDB
- Mongoose
- Multer
- ImageKit
- CORS

## ğŸ“ License

This project is open source and available under the [MIT License](LICENSE).

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“ Support

If you encounter any issues or have questions, please open an issue on the GitHub repository.
